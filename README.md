ğŸ¬ Sakila Database Chat (Local LLM + LangGraph)
A fully local, offline Text-to-SQL chat application built on the Sakila MySQL database using LangGraph, LangChain, FastAPI, Streamlit, and a local Ollama LLM.
The app converts natural-language questions into safe, read-only SQL, executes them on MySQL, and returns human-readable answers â€” without sending any data to the internet.
âœ¨ Features
ğŸ” 100% local & offline (no APIs, no cloud)
ğŸ¤– Local LLM via Ollama (qwen2.5:14b)
ğŸ§  Natural Language â†’ SQL â†’ Answer
ğŸ§± Strong SQL safety (SELECT-only, schema-aware)
ğŸ” Stateful workflow with LangGraph
ğŸš€ FastAPI backend
ğŸ’¬ Streamlit chat UI + optional HTML UI
ğŸ“Š Automatic table rendering for query results
ğŸ—„ï¸ Live schema loading from MySQL
ğŸ—ï¸ Architecture
User (Browser / Streamlit)
        |
        v
     FastAPI
        |
        v
   LangGraph Flow
        |
        v
+----------------------+
|  Text â†’ SQL (LLM)    |
|  - Uses DB schema    |
|  - Strict rules     |
+----------------------+
        |
        v
   SQL Safety Check
        |
        v
     MySQL (Sakila)
        |
        v
+----------------------+
| SQL â†’ NL Answer     |
|  - Uses only result |
+----------------------+
        |
        v
     Final Response
ğŸ§© Tech Stack
Layer	Technology
LLM Runtime	Ollama
Model	qwen2.5:14b
Orchestration	LangGraph
LLM Framework	LangChain
Backend	FastAPI
Frontend	Streamlit / HTML
Database	MySQL (Sakila)
ğŸ“ Project Structure
sakila-chat/
â”‚
â”œâ”€â”€ app.py          # FastAPI backend + LangGraph
â”œâ”€â”€ ui.py           # Streamlit chat UI
â”œâ”€â”€ index.html      # Optional HTML frontend
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
âš™ï¸ Prerequisites
Python 3.10 or 3.11 (recommended)
MySQL Server
Sakila database loaded
Ollama installed
ğŸ§  Install Ollama & Model
Install Ollama
ğŸ‘‰ https://ollama.com/download
Verify installation:
ollama --version
Download the model (one-time)
ollama pull qwen2.5:14b
ğŸ Python Setup
Create virtual environment
macOS / Linux
python -m venv venv
source venv/bin/activate
Windows
python -m venv venv
venv\Scripts\activate
Install dependencies
pip install fastapi uvicorn streamlit mysql-connector-python sqlparse
pip install langchain langgraph langchain-ollama
ğŸ—„ï¸ Database Setup
Ensure Sakila DB exists and credentials match app.py:
MYSQL_CONFIG = {
    "host": "localhost",
    "user": "sakila_user",
    "password": "sakila_pass",
    "database": "sakila"
}
Grant read-only access:
GRANT SELECT ON sakila.* TO 'sakila_user'@'localhost';
FLUSH PRIVILEGES;
â–¶ï¸ How to Run (IMPORTANT ORDER)
Terminal 1 â€” Start Ollama
ollama serve
Terminal 2 â€” Start FastAPI
uvicorn app:app --reload
API endpoint:
http://127.0.0.1:8000/chat
Terminal 3 â€” Start Streamlit UI
streamlit run ui.py
Open in browser:
http://localhost:8501
ğŸŒ Optional: HTML UI
Open index.html in your browser.
It calls the FastAPI backend at /chat.
ğŸ§ª Example Questions
List 5 films with their rental rate
Top 10 customers by total payment
Which category has the most films?
Actors who appeared in more than 20 films
ğŸ” SQL Safety Rules
âœ… SELECT statements only
âŒ No INSERT / UPDATE / DELETE
âŒ No SELECT *
âœ… Explicit JOINs required
âœ… Schema-validated tables & columns
âœ… Result limits enforced
If a question cannot be answered:
CANNOT_ANSWER
ğŸ“´ Offline Guarantee
After pulling the model:
âŒ No internet required
âŒ No API keys
âŒ No cloud services
âœ… All data stays local
ğŸš€ Future Enhancements
Schema caching for performance
SQL execution timeouts
Docker & docker-compose
Authentication & multi-user support
Query visualization
Result-only mode (skip explanation LLM)
ğŸ“œ License
MIT (or your preferred license)
